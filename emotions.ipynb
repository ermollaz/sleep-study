{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Load your CSV file containing emotion labels and texts.\n",
    "df = pd.read_csv(\"data/emotions.csv\")\n",
    "\n",
    "# Determine the number of unique labels.\n",
    "unique_labels = df['label'].unique()\n",
    "num_labels = len(unique_labels)\n",
    "\n",
    "# Set your desired total number of samples.\n",
    "total_samples = 500\n",
    "\n",
    "# Compute the number of samples per label.\n",
    "samples_per_label = total_samples // num_labels\n",
    "\n",
    "# Use groupby and sample to get a balanced dataset.\n",
    "balanced_df = df.groupby('label', group_keys=False).apply(\n",
    "    lambda group: group.sample(n=samples_per_label, random_state=42)\n",
    ")\n",
    "\n",
    "# Extract texts and labels.\n",
    "balanced_texts = balanced_df['text'].tolist()\n",
    "balanced_labels = balanced_df['label'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "embeddings_path = f\"data/model/input/emotions_embeddings_{total_samples}.pkl\"\n",
    "labels_path = f\"data/model/labels/emotions_labels_{total_samples}.pkl\"\n",
    "\n",
    "if os.path.exists(embeddings_path):\n",
    "    with open(embeddings_path, \"rb\") as f:\n",
    "        emotions_embeddings = pickle.load(f)\n",
    "else:\n",
    "    # Generate embeddings for the balanced texts.\n",
    "    emotions_embeddings = await utils.batch_generate_embeddings(balanced_texts)\n",
    "    with open(embeddings_path, \"wb\") as f:\n",
    "        pickle.dump(emotions_embeddings, f)\n",
    "\n",
    "\n",
    "if os.path.exists(labels_path):\n",
    "    with open(labels_path, \"rb\") as f:\n",
    "        emotions_labels = pickle.load(f)\n",
    "else:    \n",
    "    # Save the labels to a file.\n",
    "    with open(labels_path, \"wb\") as f:\n",
    "        pickle.dump(balanced_labels, f)\n",
    "\n",
    "\n",
    "with open(\"embedded_tasks.pkl\", \"rb\") as f:\n",
    "    tasks_data = pickle.load(f)\n",
    "\n",
    "tasks = [Task(**data) for data in tasks_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_embedding\n",
    "from importlib import reload\n",
    "import filter\n",
    "reload(filter)\n",
    "# 3. Initialize the EmotionPredictor with the embeddings and labels.\n",
    "predictor = filter.EmotionPredictor(emotions_embeddings, balanced_labels)\n",
    "\n",
    "# 4. Define the model architecture.\n",
    "predictor.define_model(hidden_size1=500, hidden_size2=150, hidden_size3=25, model_path=\"./emotions_model.pth\")\n",
    "\n",
    "# 5. Train the model.\n",
    "predictor.train_model(epochs=200, lr=0.01)\n",
    "\n",
    "# 6. Evaluate the model on the test set.\n",
    "predictor.evaluate_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from importlib import reload\n",
    "reload(utils)\n",
    "embedding = reports[2].run[1].embeddings\n",
    "# text_en = await utils.generate_completion(text,agent=\"translator\", model=\"gpt-4o-mini\")\n",
    "# new_embeddings = await generate_embedding(text)\n",
    "probabilities = predictor.predict(embedding)\n",
    "print(f\"\"\"\n",
    "Predicted probabilities for each emotion for the following text:\n",
    "{reports[2].run[1].report}\n",
    "\n",
    "sadness: {probabilities[0][0]}, \n",
    "joy: {probabilities[0][1]},\n",
    "love: {probabilities[0][2]},\n",
    "anger: {probabilities[0][3]},\n",
    "fear: {probabilities[0][4]},\n",
    "surprise: {probabilities[0][5]}  \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Define emotion names (order must match the predictor's output).\n",
    "emotion_names = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "angles = emotion_names + [emotion_names[0]]  # Close the polygon.\n",
    "\n",
    "# Dictionary to collect classification counts per condition.\n",
    "# Key: condition (e.g. \"Condition 1\"), Value: dictionary of counts for each emotion.\n",
    "condition_counts = {}\n",
    "\n",
    "for report in reports:\n",
    "    for run in report.run:\n",
    "        if run.embeddings is not None and run.report.strip() != \"\":\n",
    "            emb = np.array(run.embeddings)\n",
    "            probs = predictor.predict(emb)\n",
    "            predicted_idx = np.argmax(probs)\n",
    "            predicted_emotion = emotion_names[predicted_idx]\n",
    "            \n",
    "            # Only use the first condition for this run.\n",
    "            cond_value = report.condition[0]\n",
    "            cond_key = f\"Condition {cond_value}\"\n",
    "            if cond_key not in condition_counts:\n",
    "                condition_counts[cond_key] = {emotion: 0 for emotion in emotion_names}\n",
    "            condition_counts[cond_key][predicted_emotion] += 1\n",
    "\n",
    "# Optionally, you might want to convert counts to percentages.\n",
    "# For each condition, divide each count by the total counts for that condition.\n",
    "condition_percentages = {}\n",
    "for cond, counts in condition_counts.items():\n",
    "    total = sum(counts.values())\n",
    "    # Avoid division by zero.\n",
    "    if total > 0:\n",
    "        condition_percentages[cond] = {emotion: count/total for emotion, count in counts.items()}\n",
    "    else:\n",
    "        condition_percentages[cond] = {emotion: 0 for emotion in emotion_names}\n",
    "\n",
    "# For demonstration, here we'll create radar charts to display the percentages.\n",
    "# Create a subplot with 1 row and as many columns as conditions.\n",
    "sorted_conditions = sorted(condition_percentages.keys())\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=len(sorted_conditions),\n",
    "    specs=[[{'type': 'polar'}] * len(sorted_conditions)],\n",
    "    subplot_titles=[f\"{cond}\" for cond in sorted_conditions]\n",
    ")\n",
    "\n",
    "# Define colors for conditions.\n",
    "colors = {\n",
    "    \"Condition 1\": \"red\",\n",
    "    \"Condition 2\": \"blue\",\n",
    "    \"Condition 3\": \"green\"\n",
    "}\n",
    "\n",
    "for i, cond in enumerate(sorted_conditions):\n",
    "    # Extract percentages in the order of emotion_names.\n",
    "    percentages = [condition_percentages[cond][emotion] for emotion in emotion_names]\n",
    "    # Close the polygon by appending the first value.\n",
    "    percentages_closed = percentages + [percentages[0]]\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=percentages_closed,\n",
    "        theta=angles,\n",
    "        mode='lines+markers',\n",
    "        name=f'{cond}',\n",
    "        line=dict(color=colors.get(cond, \"black\"))\n",
    "    ), row=1, col=i+1)\n",
    "\n",
    "tickvals = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]\n",
    "ticktext = [\"0.0\", \"0.1\", \"0.2\", \"0.3\", \"0.4\", \"0.5\", \"0.6\", \"0.7\", \"0.8\", \"0.9\", \"1.0\"]\n",
    "\n",
    "num_conditions = len(sorted_conditions)\n",
    "for i in range(1, num_conditions + 1):\n",
    "    polar_id = f\"polar{i}\" if i > 1 else \"polar\"\n",
    "    fig.update_layout({\n",
    "        polar_id: dict(\n",
    "            radialaxis=dict(\n",
    "                tickmode=\"array\",\n",
    "                tickvals=tickvals,\n",
    "                ticktext=ticktext,\n",
    "                range=[0, 1],\n",
    "                autorange=\"reversed\"\n",
    "            )\n",
    "        )\n",
    "    })\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
