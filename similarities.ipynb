{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analyzing Task-Report Similarities Using Text Embeddings and Cosine Similarity**\n",
    "\n",
    "## **Description**\n",
    "This notebook processes task descriptions and experimental reports, extracts text embeddings, and computes cosine similarity scores between tasks and reports. The similarity scores are grouped by experimental conditions and visualized using Kernel Density Estimation (KDE) to explore patterns in textual similarity.\n",
    "\n",
    "## **Rationale**\n",
    "The goal of this analysis is to assess the relationship between task descriptions and reports generated during experiments. By embedding textual data and using cosine similarity, we can quantify how closely a report aligns with predefined tasks under different experimental conditions. This approach enables:\n",
    "- Automated comparison of structured and unstructured text data.\n",
    "- Identification of condition-dependent text similarities.\n",
    "- Visualization of similarity distributions for interpretability.\n",
    "\n",
    "The workflow follows a structured approach:\n",
    "1. **Data Loading**: Extracts task descriptions and experimental reports from `.docx` files.\n",
    "2. **Data Processing**: Cleans and organizes text, identifying experimental runs.\n",
    "3. **Embedding Generation**: Converts text into vector embeddings using openai `text-embedding-large` model\n",
    "4. **Similarity Computation**: Measures cosine similarity between task and report embeddings.\n",
    "5. **Analysis & Visualization**: Groups similarities by experimental condition and visualizes distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports and Data Models**\n",
    "This cell initializes the notebook by importing essential libraries, defining helper functions, and structuring data models.  \n",
    "- **Imports:** Includes standard libraries (`os`, `re`, `pickle`, `numpy`, `scipy.stats`, `pandas`) along with external dependencies (`pydantic`, `docx`, `plotly.graph_objects`, and a custom `utils` module).  \n",
    "- **Helper Function:** Implements `cosine_similarity()` to compute similarity between two vectors using the cosine similarity metric.  \n",
    "- **Data Models:**  \n",
    "  - `Run`: Represents an experimental run with a run number, report text, and optional embeddings.  \n",
    "  - `Report`: Defines a collection of runs associated with a specific report name and conditions.  \n",
    "  - `Task`: Stores task-related information, including a name, description, and optional embeddings.  \n",
    "- **Paths & Naming:** Defines paths for raw and interim data storage, task names, a mapping of condition labels, and colors for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Imports\n",
    "#####\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "import os\n",
    "from docx import Document\n",
    "import re\n",
    "import utils\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#####\n",
    "# Helper functions\n",
    "#####\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Compute the cosine similarity between two vectors.\"\"\"\n",
    "    v1 = np.array(vec1)\n",
    "    v2 = np.array(vec2)\n",
    "    norm1 = np.linalg.norm(v1)\n",
    "    norm2 = np.linalg.norm(v2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        return 0.0\n",
    "    return np.dot(v1, v2) / (norm1 * norm2)\n",
    "\n",
    "#####\n",
    "# Datamodels\n",
    "#####\n",
    "class Run(BaseModel):\n",
    "    run_number: int\n",
    "    report: str\n",
    "    embeddings: Optional[List[float]] = None\n",
    "\n",
    "class Report(BaseModel):\n",
    "    name: str\n",
    "    run: List[Run]\n",
    "    condition: List[str]\n",
    "\n",
    "class Task(BaseModel):\n",
    "    task_name: str\n",
    "    description: str\n",
    "    embeddings: Optional[List[float]] = None\n",
    "\n",
    "#####\n",
    "# Paths & Naming\n",
    "#####\n",
    "\n",
    "condition_path = \"data/raw/conditions.xlsx\"\n",
    "task_directory = \"data/raw/tasks\"\n",
    "report_directory = \"data/raw/reports\"\n",
    "embedded_reports = \"data/interim/reports.pkl\"\n",
    "embedded_tasks = \"data/interim/tasks.pkl\"\n",
    "task_names = [\"Gehen\",\"Schreibtisch\",\"Tisch\"]\n",
    "conditions_map = {\n",
    "    1: \"complete\",\n",
    "    2: \"incomplete\",\n",
    "    3: \"interrupted\"\n",
    "}\n",
    "colors = [\n",
    "    \"rgba(255, 0, 0, 0.6)\", # red\n",
    "    \"rgba(0, 255, 0, 0.6)\", # green\n",
    "    \"rgba(0, 0, 255, 0.6)\" # blue\n",
    "    ]\n",
    "with open(embedded_tasks, \"rb\") as f:\n",
    "    tasks_data = pickle.load(f)\n",
    "tasks = [Task(**data) for data in tasks_data]\n",
    "\n",
    "with open(embedded_reports, \"rb\") as f:\n",
    "    report_data = pickle.load(f)\n",
    "reports = [Report(**data) for data in report_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load and Filter Condition Data**\n",
    "- Reads an Excel file (`conditions.xlsx`) containing experimental condition data.  \n",
    "- Filters the dataset to include only entries where the `Experimentator` is `\"Maren\"` and the `Metric` is `\"full_text\"`.  \n",
    "- Creates a dictionary (`condition_dict`) mapping participants (`Proband`), tasks, and conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(condition_path, sheet_name='table incl full_text')\n",
    "df_restricted = df[(df['Experimentator'] == 'Maren')& (df['Metric'] == \"full_text\")]\n",
    "condition_dict = df_restricted[['Proband', 'Task', 'Condition']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Load and Process Task Descriptions**\n",
    "- Lists all `.docx` files in the `task_directory`.  \n",
    "- Iterates through each task document, extracts its text, and stores it in a `Task` object.  \n",
    "- The task descriptions are stored in a list, associating each with a predefined task name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all .docx files in the directory\n",
    "task_files = [f for f in os.listdir(task_directory) if f.endswith('.docx')]\n",
    "tasks = []\n",
    "# Iterate over each file and extract text\n",
    "for idx, file in enumerate(task_files, 0):\n",
    "    file_path = os.path.join(task_directory, file)\n",
    "    doc = Document(file_path)\n",
    "    text = \"\"\n",
    "    for para in doc.paragraphs:\n",
    "        # Create a Task object for each paragraph\n",
    "        text += para.text\n",
    "    task = Task(task_name=f\"{[task_names[idx]]}\", description=text)\n",
    "    tasks.append(task)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load and Process Reports**\n",
    "- Scans subdirectories in `report_directory` to find `.docx` report files that start with `\"M\"`.  \n",
    "- Extracts the participant identifier (`Proband`) from the filename.  \n",
    "- Iterates through each document, identifying experimental runs using specific markers (e.g., `\"INT-Pb21-W1\"`).  \n",
    "- Splits the text into runs and maps them to their corresponding participant conditions using `condition_dict`.  \n",
    "- Constructs a `Report` object with the extracted runs and associated conditions, appending it to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all subdirectories in the report directory\n",
    "subdirs = [d for d in os.listdir(report_directory) if os.path.isdir(os.path.join(report_directory, d))]\n",
    "# List all .docx files in the subdirectories that start with \"M\"\n",
    "report_files = [\n",
    "    f\"{report_directory}/{subdir}/{f}\" # File path\n",
    "    for subdir in subdirs # Subdirectory\n",
    "    for f in os.listdir(os.path.join(report_directory, subdir)) # File\n",
    "    if f.endswith('.docx') and subdir.startswith(\"M\") # Filter\n",
    "    ]\n",
    "reports = []\n",
    "for file_path in report_files:\n",
    "    doc = Document(file_path)\n",
    "    report_name = re.search(r'\\d+', file_path).group()\n",
    "    runs = []\n",
    "    current_run_text = []\n",
    "    current_run_number = None\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        # Check if the paragraph is a run marker (e.g., \"INT-Pb21-W1\")\n",
    "        if text.startswith(\"INT-\") and \"-W\" in text:\n",
    "            # If there's an active run, save it before starting a new one\n",
    "            if current_run_number is not None:\n",
    "                raw_text = \"\\n\".join(current_run_text).strip()\n",
    "                runs.append(Run(\n",
    "                    run_number=current_run_number,\n",
    "                    report=raw_text, \n",
    "                ))\n",
    "            # Extract the run number from the marker using regex\n",
    "            match = re.search(r'-W(\\d+)', text)\n",
    "            current_run_number = int(match.group(1)) if match else None\n",
    "            current_run_text = []  # Reset the run text accumulator\n",
    "        else:\n",
    "            # Otherwise, accumulate text for the current run\n",
    "            current_run_text.append(text)\n",
    "    \n",
    "    # Add the last run if it exists\n",
    "    if current_run_number is not None and current_run_text:\n",
    "        runs.append(Run(\n",
    "            run_number=current_run_number,\n",
    "            report=\"\\n\".join(current_run_text).strip()\n",
    "        ))\n",
    "    conditions = [entry[\"Condition\"] for entry in condition_dict if entry[\"Proband\"] == int(report_name)]\n",
    "    # Create the Report object using the correct field name 'run'\n",
    "    report = Report(name=report_name, run=runs, condition=[conditions_map[num][0] for num in conditions[:3]])\n",
    "    reports.append(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate and Store Text Embeddings**\n",
    "- Extracts task descriptions and asynchronously generates their embeddings using `utils.batch_generate_embeddings()`.  \n",
    "- Iterates through each `Report`, processing its runs to generate embeddings for the run text.  \n",
    "- Saves the processed `reports` and `tasks` as pickled files (`reports.pkl`, `tasks.pkl`) for later use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Task embeddings\n",
    "task_texts = [task.description for task in tasks]\n",
    "# Generate embeddings asynchronously for all tasks at once\n",
    "tasks_embeddings = await utils.batch_generate_embeddings(task_texts)\n",
    "# Update each Task with its corresponding embedding\n",
    "for task, emb in zip(tasks, tasks_embeddings):\n",
    "    task.embeddings = emb\n",
    "\n",
    "# Process Report Run embeddings\n",
    "for report in reports:\n",
    "    run_texts = [run.report for run in report.run]\n",
    "    if run_texts:  # Only process if there are runs in the report\n",
    "        runs_embeddings = await utils.batch_generate_embeddings(run_texts)\n",
    "        for run, emb in zip(report.run, runs_embeddings):\n",
    "            run.embeddings = emb\n",
    "\n",
    "\n",
    "# Cache the embedded reports and tasks\n",
    "with open(embedded_reports, \"wb\") as f:\n",
    "    pickle.dump([report.dict() for report in reports], f)\n",
    "\n",
    "with open(embedded_tasks, \"wb\") as f:\n",
    "    pickle.dump([task.dict() for task in tasks], f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Compute Similarity Scores**\n",
    "- Iterates through reports and their corresponding runs.  \n",
    "- Computes cosine similarity scores between each run's embeddings and task embeddings.  \n",
    "- Groups similarity scores by experimental conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate similarity scores overall (ignoring tasks) but grouped by condition.\n",
    "similarity_by_condition = {}\n",
    "\n",
    "for report in reports:\n",
    "    for run in report.run:\n",
    "        # Skip runs with empty text or missing embeddings.\n",
    "        if not run.report.strip() or run.embeddings is None:\n",
    "            continue\n",
    "        for idx, task in enumerate(tasks):\n",
    "            if task.embeddings is None:\n",
    "                continue\n",
    "            score = cosine_similarity(run.embeddings, task.embeddings)\n",
    "            similarity_by_condition.setdefault(report.condition[idx], []).append(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualize Similarity Distributions**\n",
    "- Initializes a Plotly figure to visualize the cosine similarity distributions by condition.  \n",
    "- Uses Gaussian Kernel Density Estimation (KDE) to estimate similarity score distributions.  \n",
    "- Normalizes density values for consistent visualization.  \n",
    "- Assigns colors to each condition and plots filled curves representing similarity distributions.  \n",
    "- Displays the final interactive figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "# Define colors for conditions.\n",
    "color_map = {cond:colors[i] for i, cond in enumerate(conditions_map.values())}\n",
    "# For each condition, compute the KDE and add a filled trace.\n",
    "for cond, sim_list in similarity_by_condition.items():\n",
    "    data = sim_list\n",
    "    if not data:\n",
    "        continue\n",
    "    kde = st.gaussian_kde(data)\n",
    "    x_vals = np.linspace(0, 1, 200)\n",
    "    y_vals = kde(x_vals)\n",
    "    # Normalize the density values (scaled to a max height of 0.8 for visual consistency)\n",
    "    y_vals_norm = (y_vals - np.min(y_vals)) / (np.max(y_vals) - np.min(y_vals)) * 0.8\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_vals,\n",
    "        y=y_vals_norm,\n",
    "        mode=\"lines\",\n",
    "        line_shape=\"spline\",\n",
    "        fill=\"tozeroy\",\n",
    "        line=dict(color=color_map.get(cond), width=2),\n",
    "        fillcolor=color_map.get(cond),\n",
    "        name=cond\n",
    "    ))\n",
    "\n",
    "# Update layout.\n",
    "fig.update_layout(\n",
    "    title=\"Cosine Similarity Distributions by Condition\",\n",
    "    xaxis_title=\"Cosine Similarity\",\n",
    "    yaxis_title=\"Normalized Density\",\n",
    "    template=\"plotly_white\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(l=50, r=50, t=100, b=50)\n",
    ")\n",
    "fig.update_xaxes(range=[0, 1])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
